---
title: "Challenge B"
author: "Valentin Burban & Victor Vasse"
date: "4 décembre 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

https://github.com/valentinburbanut1/R-Challenge-B

```{r load package, include=FALSE}
library(lmtest)
library(pander)
library(car)
library(sandwich)
library(readr)
library(randomForest)
library(tidyverse)
library(dplyr)
library(np)
library(caret)
```

## Task 1B - Predicting house prices in Ames, Iowa (continued)

```{r, step21, include=FALSE}
train <-  read.csv(file = file.choose())
# here i summarize the data set using the function sum(is.na()); is.na(.) 
# it gives me a column that is equal to TRUE when the row has a missing value (NA) or FALSE when it doesn't, so sum(is.na(.)) gives me the number of missing values for a column,
#then i gather the data to make it nicer, then i drop all the variables that do not have missing observations
train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)

#I remove the variables that have more than 100 missing observations
#Except Fence or Alley maybe, there are not very critical for determining the price of a house:
remove.vars <- train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 100) %>% select(feature) %>% unlist
train <- train %>% select(- one_of(remove.vars))

#For the rest of the variables with missing values, I remove the observations with the missing values
train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)
train <- train %>% filter(is.na(GarageType) == FALSE, is.na(MasVnrType) == FALSE, is.na(BsmtFinType2) == FALSE, is.na(BsmtExposure) == FALSE, is.na(Electrical) == FALSE)


train.rf <- randomForest(SalePrice ~ . -Id, data = train, ntree = 500, na.action = na.roughfix)
print(train.rf)

test <- read.csv(file = file.choose())
common <- intersect(names(train), names(test))
for (p in common) {
  if (class(train [[p]]) == "factor") {
    levels(test[[p]]) <- levels(train[[p]])
  }
}


lm_model_2 <- lm(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train)
summary(lm_model_2)
prediction <- data.frame(Id = test$Id, SalePrice_predict = predict(lm_model_2, test, type="response"))
prediction <- prediction[,2]

# Use the model that I just chose to make predictions for the test set
predict <- data.frame(Id = test$Id, SalePrice_predict = predict(train.rf, test, type="response"))
predict <- predict[,2]
```

### Step 1 - Choose a ML technique : non-parametric kernel estimation, random forests, etc. . . Give a brief intuition of how it works

We choose randomForest technique. In fact, this method generate a forest (ie several decision trees) %in% a random way. So, there is a multitude of week model that they are combined to build a strong one. Mecanisum, If we want n trees, n subsets of our datas are randomly taken, with replacement. So, %in% average, this correspond to the random sampling of %63,2% percentages of the population. For each subset, a decision tree is created, with some nodes, branch.  Some segmentation variables are randomly choosen, and the tree is splited according to the best segmentation.  Then, when news datas are implement %in% our model, they will be evaluation by all the trees.

###Step 2 - Train the chosen technique on the training data. Hint : packages np for non-parametric regressions, randomForest for random forests. Don't use the variable Id as a feature. 

As a first step, we clean our data : detection and suppression of N/A observations. Then, we launch a regression : train.rf.

###Step 3 - Make predictions on the test data, and compare them to the predictions of a linear regression of your choice.

3 For the last step, we have choosen the following regression : lm(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train). As a comparaison, we can take this informations :

``` {r, answer 1.3.1, echo = FALSE}
pander(summary(predict))
pander(summary(prediction))
```

In the first table we find the relative informations about the randomForest predictions model. In the second table we find the relative informations about the linear predictions model. 

##Task 2B - Overfitting in Machine Learning (continued)

###Step 4 - Between the two models, which predictions are more variable? Which predictions have the least bias?

We can see that the variance of lowflex model is lower than the variance of highflex model (2.764222 against 7.569123). 
Moreover, the biais of highflex is larger than the biais of lowflex (0.1022669 against 0.09576519)

###Step 5 - Plot the scatterplot of x-y, along with the predictions of ll.fit.lowflex and ll.fit.highflex now using the test data. Which predictions are more variable? What happened to the bias of the least biased model?

We have computed variances of both predictions. We observe that the variance associate at the prediction with highflex model is higher than the variances of lowflex model. (6.582451 against 2.572402). Moreover, the biais of the highflex model is : 0.1227896, whereas the biais of lowflex is -0.08512817. Then, we observe that the biais of the least biased model becomes negative. 

###Step 7 - Estimate a local linear model y ~ x on the training data with each bandwidth.

For this step, we use the function : lapply, in a purpose to avoid for loop, which take more time. 

###Step 10 - Draw on the same plot how the MSE on training data, and test data, change when the bandwidth increases. Conclude.

We observe that, the "training MSE" takes its minimal value when the bandwidth is close to zero. The "test MSE" takes its minimal value when bandwidth is around 0.23.

##Task 3B - Privacy regulation compliance in France

###Step 1 - Import the CNIL dataset from the Open Data Portal. (1 point)

We have to report time of our compilations. 
For the first import : 
## user   system elapsed
## 661.71 210.21 1049.96

For the second import : 
## user system elapsed
## 1.87 0.01 1.92

###Step 2 - Show a (nice) table with the number of organizations that has nominated a CNIL per department. HINT : A department in France is uniquely identified by the first two digits of the postcode. 

In this question, we did an euclidean division to have only the departement. Then, we used the function : table to sort and count by departments in a nice table

###Step 3 - Merge the information from the SIREN dataset into the CNIL data. Explain the method you use. HINT : In the SIREN dataset, there are some rows that refer to the same SIREN number, use the most up to date information about each company.

In this case, we will do like SQL (with left inner join). To do that, we used the function merge. Then a new table is created, with observations that we want.




